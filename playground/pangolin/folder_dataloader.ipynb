{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import h5py\n",
    "import pickle\n",
    "import fnmatch\n",
    "import cv2\n",
    "import sys\n",
    "from time import time\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "act_path = \"/home/zfei/code/act-plus-plus/\"\n",
    "sys.path.append(act_path)\n",
    "from utils import EpisodicDataset\n",
    "from utils import find_all_hdf5, flatten_list, get_norm_stats\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51 hdf5 files\n"
     ]
    }
   ],
   "source": [
    "dataset_path_list = find_all_hdf5(\"/mnt/data1/act/train_act_scara_3cam/data1/\", skip_mirrored_data=False)\n",
    "norm_stats, all_episode_len = get_norm_stats(dataset_path_list)\n",
    "\n",
    "camera_names = ['wrist', 'wrist_down', 'top']\n",
    "train_episode_ids = [0, 1]\n",
    "train_episode_len = [all_episode_len[i] for i in train_episode_ids]\n",
    "\n",
    "chunk_size = 64\n",
    "policy_class = \"EPACT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URDF Path:  /home/zfei/code/act-plus-plus/urdf/hitbot_model.urdf\n",
      "kdl_parse urdf ok?:  True\n",
      "augment_images:  False\n",
      "Initializing transformations\n"
     ]
    }
   ],
   "source": [
    "train_dataset = EpisodicDataset(dataset_path_list, \n",
    "                                camera_names, \n",
    "                                norm_stats, \n",
    "                                train_episode_ids, \n",
    "                                train_episode_len, \n",
    "                                chunk_size, \n",
    "                                policy_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_datafolder(dataset_dir):\n",
    "    datafolders = []\n",
    "    for root, dirs, files in os.walk(dataset_dir, followlinks=True):\n",
    "        for dirname in fnmatch.filter(dirs, 'seg_*'):\n",
    "            datafolders.append(os.path.join(root, dirname))\n",
    "    print(f'Found {len(datafolders)} datafolders under {dataset_dir}')\n",
    "    return datafolders\n",
    "\n",
    "def get_norm_stats_folder(dataset_path_list):\n",
    "    all_pose_data = []\n",
    "    all_grip_data = []\n",
    "    all_episode_len = []\n",
    "\n",
    "    for dataset_path in dataset_path_list:\n",
    "        try:\n",
    "            action = np.loadtxt(dataset_path + \"/gripper_distances.txt\").reshape(-1, 1)\n",
    "            camera_trajs = np.loadtxt(dataset_path + \"/CameraTrajectory.txt\")\n",
    "            camera_trajs_mat = camera_trajs.reshape(-1, 3, 4)\n",
    "            pose = np.zeros((len(camera_trajs), 6))\n",
    "            pose[:, :3] = camera_trajs_mat[:, :3, 3]\n",
    "            euler_angles = rotation_matrix_to_euler_angles(camera_trajs_mat[:, :3, :3])\n",
    "            pose[:, 3:] = euler_angles\n",
    "        except Exception as e:\n",
    "            print(f'Error loading {dataset_path} in get_norm_stats')\n",
    "            print(e)\n",
    "            quit()\n",
    "        all_pose_data.append(torch.from_numpy(pose))\n",
    "        all_grip_data.append(torch.from_numpy(action))\n",
    "        all_episode_len.append(len(action))\n",
    "    all_pose_data = torch.cat(all_pose_data, dim=0)\n",
    "    all_grip_data = torch.cat(all_grip_data, dim=0)\n",
    "    # cat pose and grip data\n",
    "    all_action_data = torch.cat([all_pose_data, all_grip_data], dim=1)\n",
    "\n",
    "    # normalize action data\n",
    "    action_mean = all_action_data.mean(dim=[0]).float()\n",
    "    action_std = all_action_data.std(dim=[0]).float()\n",
    "    action_std = torch.clip(action_std, 1e-2, np.inf) # clipping\n",
    "    action_min = all_action_data.min(dim=0).values.float()\n",
    "    action_max = all_action_data.max(dim=0).values.float()\n",
    "\n",
    "    eps = 0.0001\n",
    "    stats = {\"action_mean\": action_mean.numpy(), \"action_std\": action_std.numpy(),\n",
    "             \"action_min\": action_min.numpy() - eps,\"action_max\": action_max.numpy() + eps}\n",
    "\n",
    "    return stats, all_episode_len\n",
    "\n",
    "def rotation_matrix_to_euler_angles(rotation_matrices):\n",
    "    \"\"\"Converts a batch of rotation matrices to Euler angles (roll, pitch, yaw).\n",
    "\n",
    "    Args:\n",
    "    rotation_matrices: A list of 3x3 rotation matrices.\n",
    "\n",
    "    Returns:\n",
    "    A list of Euler angles (roll, pitch, yaw) corresponding to each rotation matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    rotations = Rotation.from_matrix(rotation_matrices)\n",
    "    euler_angles = rotations.as_euler('xyz', degrees=False)\n",
    "    return euler_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41 datafolders under /home/zfei/data/UPI/lab_sb/rs435i_lab_picking_024-08-29-09-07-12/grip_data_seg/\n"
     ]
    }
   ],
   "source": [
    "dataset_path_list = find_all_datafolder(\"/home/zfei/data/UPI/lab_sb/rs435i_lab_picking_024-08-29-09-07-12/grip_data_seg/\")\n",
    "norm_stats, all_episode_len  = get_norm_stats_folder(dataset_path_list)\n",
    "\n",
    "camera_names = ['color']\n",
    "train_episode_ids = [0, 1]\n",
    "train_episode_len = [all_episode_len[i] for i in train_episode_ids]\n",
    "\n",
    "chunk_size = 64\n",
    "policy_class = \"ACTEP\"\n",
    "policy_class = \"ACT\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import EpisodicDatasetRs435i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment_images:  False\n",
      "episode_id:  0\n",
      "start_ts:  0\n",
      "Initializing transformations\n"
     ]
    }
   ],
   "source": [
    "dataset = EpisodicDatasetRs435i(dataset_path_list, camera_names, norm_stats, train_episode_ids, train_episode_len, chunk_size, policy_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode_id:  0\n",
      "start_ts:  50\n"
     ]
    }
   ],
   "source": [
    "image_data, action_data, is_pad = dataset[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 480, 848])\n",
      "torch.Size([64, 7])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "print(image_data.shape)\n",
    "print(action_data.shape)\n",
    "print(is_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
