{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import sys, os\n",
    "import cv2 as cv\n",
    "import h5py\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import transformations as tf\n",
    "import numpy as np\n",
    "from itertools import repeat\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No private macro file found!\n",
      "    It is recommended to use a private macro file\n",
      "    To setup, run: python /home/zfei/code/robomimic/robomimic/scripts/setup_macros.py\n",
      ")\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "act_path = \"/home/zfei/code/act-plus-plus/\"\n",
    "sys.path.append(act_path)\n",
    "from policy import EPACTPolicy, ACTPolicy, DINOPolicy\n",
    "from brl_constants import TASK_CONFIGS\n",
    "from utils import EpisodicDataset\n",
    "from utils import find_all_hdf5, flatten_list, get_norm_stats\n",
    "from utils import load_data, load_data_fix_val # data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/mnt/data1/act/train_act_scara_3cam/3cam_epact_v4_1_lep10/\"\n",
    "config_path = ckpt_path + \"config.pkl\"\n",
    "\n",
    "with open(config_path, \"rb\") as f:\n",
    "    policy_config = pickle.load(f)['policy_config']\n",
    "    policy_config[\"ep_weight\"] = 1.0\n",
    "\n",
    "act_policy_config = copy.copy(policy_config)\n",
    "dino_policy_config = copy.copy(policy_config)\n",
    "\n",
    "act_policy_config['hidden_dim'] = 384\n",
    "policy_class = \"DINOACT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51 hdf5 files\n"
     ]
    }
   ],
   "source": [
    "dataset_path_list = find_all_hdf5(\"/mnt/data1/act/train_act_scara_3cam/data1/\", skip_mirrored_data=False)\n",
    "norm_stats, all_episode_len = get_norm_stats(dataset_path_list)\n",
    "\n",
    "camera_names = ['wrist', 'wrist_down', 'top']\n",
    "train_episode_ids = [0, 1]\n",
    "train_episode_len = [all_episode_len[i] for i in train_episode_ids]\n",
    "\n",
    "val_episode_ids = [0, 1]\n",
    "val_episode_len = [all_episode_len[i] for i in val_episode_ids]\n",
    "\n",
    "chunk_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/mnt/data1/act/train_act_scara_3cam\"\n",
    "DATA_DIR = '/mnt/data1/act'\n",
    "\n",
    "TASK_CONFIGS = {\n",
    "        'epact':{\n",
    "        'dataset_dir': dataset_dir + '/train_act_scara_3cam',\n",
    "        'num_episodes': 100,\n",
    "        'episode_len': 300,\n",
    "        'camera_names': ['wrist', 'wrist_down']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config = TASK_CONFIGS['epact']\n",
    "name_filter = task_config.get('name_filter', lambda n: True)\n",
    "batch_size_train = 8\n",
    "batch_size_val = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_dir:  /mnt/data1/act/train_act_scara_3cam\n",
      "Found 51 hdf5 files\n",
      "\n",
      "\n",
      "Data from: ['/mnt/data1/act/train_act_scara_3cam']\n",
      "- Train on [50] episodes\n",
      "- Test on [1] episodes\n",
      "\n",
      "\n",
      "Found 51 hdf5 files\n",
      "Norm stats from: ['/mnt/data1/act/train_act_scara_3cam']\n",
      "train_episode_len: [114, 175, 120, 154, 135, 135, 124, 104, 168, 98, 118, 121, 121, 136, 128, 125, 165, 136, 117, 140, 117, 139, 151, 123, 153, 124, 107, 110, 135, 104, 103, 161, 168, 129, 154, 111, 137, 177, 128, 101, 127, 118, 106, 116, 144, 110, 118, 108, 90, 132], val_episode_len: [116], train_episode_ids: [20 25 36 40  8 31 28 47 34  7 33 46  2 17  4 18 49 14 48 50 35 38 32 43\n",
      " 41 23  6 26 29  3 30 37 19  9 10 12  0 44 16 27  1 13 22 42 45 24 11  5\n",
      " 21 15], val_episode_ids: [39]\n",
      "val data:  /mnt/data1/act/train_act_scara_3cam/data1/episode_13.hdf5\n",
      "augment_images:  False\n",
      "Initializing transformations\n",
      "augment_images:  False\n",
      "Initializing transformations\n",
      "Augment images: False, train_num_workers: 8, val_num_workers: 8\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 100\n",
    "skip_mirrored_data = False\n",
    "load_pretrain = False\n",
    "train_ratio = 0.99\n",
    "resize = None\n",
    "resize = (518, 518)\n",
    "print(\"dataset_dir: \", dataset_dir)\n",
    "train_dataloader,val_dataloader, stats, _ = load_data_fix_val(dataset_dir, \n",
    "                                                       name_filter, \n",
    "                                                       camera_names, \n",
    "                                                       batch_size_train, \n",
    "                                                       batch_size_val, \n",
    "                                                       chunk_size,\n",
    "                                                       skip_mirrored_data,\n",
    "                                                       load_pretrain,\n",
    "                                                       policy_class,\n",
    "                                                       stats_dir_l=None,\n",
    "                                                       sample_weights=None,\n",
    "                                                       train_ratio=train_ratio,\n",
    "                                                       resize=resize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG]image torch.Size([8, 3, 3, 518, 518])\n",
      "[DEBUG]image2 torch.Size([8, 3, 3, 518, 518])\n",
      "image torch.Size([8, 3, 3, 518, 518])\n",
      "qpos torch.Size([8, 4])\n",
      "actions torch.Size([8, 100, 5])\n",
      "is_pad torch.Size([8, 100])\n",
      "[DETRVAE]: cam_id: 0, image: torch.Size([8, 3, 518, 518])\n",
      "DinoBackbone x:  torch.Size([8, 384, 1369])\n",
      "DinoBackbone x:  torch.Size([8, 384, 375])\n",
      "DinoBackbone x:  torch.Size([8, 384, 15, 25])\n",
      "DinoJoiner x:  torch.Size([8, 384, 15, 25])\n",
      "[DETRVAE]: cam_id: 0, cam_features: torch.Size([8, 384, 15, 25]), pos: torch.Size([1, 384, 15, 25])\n",
      "[DETRVAE]: cam_id: 1, image: torch.Size([8, 3, 518, 518])\n",
      "DinoBackbone x:  torch.Size([8, 384, 1369])\n",
      "DinoBackbone x:  torch.Size([8, 384, 375])\n",
      "DinoBackbone x:  torch.Size([8, 384, 15, 25])\n",
      "DinoJoiner x:  torch.Size([8, 384, 15, 25])\n",
      "[DETRVAE]: cam_id: 1, cam_features: torch.Size([8, 384, 15, 25]), pos: torch.Size([1, 384, 15, 25])\n",
      "[DETRVAE]: cam_id: 2, image: torch.Size([8, 3, 518, 518])\n",
      "DinoBackbone x:  torch.Size([8, 384, 1369])\n",
      "DinoBackbone x:  torch.Size([8, 384, 375])\n",
      "DinoBackbone x:  torch.Size([8, 384, 15, 25])\n",
      "DinoJoiner x:  torch.Size([8, 384, 15, 25])\n",
      "[DETRVAE]: cam_id: 2, cam_features: torch.Size([8, 384, 15, 25]), pos: torch.Size([1, 384, 15, 25])\n",
      "[DETRVAE]: src: torch.Size([8, 384, 15, 75])\n",
      "[DETRVAE]: pos: torch.Size([1, 384, 15, 75])\n",
      "[DETRVAE]: latent_input: torch.Size([8, 384])\n",
      "[DETRVAE]: proprio_input: torch.Size([8, 384])\n",
      "[DETRVAE]: additional_pos_embed: torch.Size([2, 384])\n",
      "[DETRVAE]: query_embed: torch.Size([100, 384])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'l1': tensor(0.4779, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " 'kl': tensor(8.3777, device='cuda:0', grad_fn=<SelectBackward0>),\n",
       " 'loss': tensor(84.2548, device='cuda:0', grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(train_dataloader)\n",
    "image_data, qpos_data, action_data, is_pad = data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
