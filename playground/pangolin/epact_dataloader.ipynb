{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import h5py\n",
    "import pickle\n",
    "import fnmatch\n",
    "import cv2\n",
    "import sys\n",
    "from time import time\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kdl_parser_py.urdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "act_path = \"/home/zfei/code/act-plus-plus/\"\n",
    "sys.path.append(act_path)\n",
    "from utils import EpisodicDataset\n",
    "from utils import find_all_hdf5, flatten_list, get_norm_stats\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51 hdf5 files\n"
     ]
    }
   ],
   "source": [
    "dataset_path_list = find_all_hdf5(\"/mnt/data1/act/train_act_scara_3cam/data1/\", skip_mirrored_data=False)\n",
    "norm_stats, all_episode_len = get_norm_stats(dataset_path_list)\n",
    "\n",
    "camera_names = ['wrist', 'wrist_down', 'top']\n",
    "train_episode_ids = [0, 1]\n",
    "train_episode_len = [all_episode_len[i] for i in train_episode_ids]\n",
    "\n",
    "chunk_size = 64\n",
    "policy_class = \"EPACT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URDF Path:  /home/zfei/code/act-plus-plus/urdf/hitbot_model.urdf\n",
      "kdl_parse urdf ok?:  True\n",
      "augment_images:  False\n",
      "ee_pose:  (65, 6)\n",
      "ee_pose:  [[ 0.    -0.     0.     0.     0.    -0.   ]\n",
      " [-0.001 -0.001 -0.    -0.     0.    -0.005]\n",
      " [ 0.    -0.001  0.    -0.     0.    -0.004]\n",
      " [-0.    -0.001  0.    -0.     0.    -0.005]\n",
      " [-0.    -0.001  0.    -0.     0.    -0.006]\n",
      " [-0.001 -0.002 -0.    -0.     0.    -0.009]\n",
      " [-0.001 -0.002 -0.    -0.     0.    -0.009]\n",
      " [-0.001 -0.002  0.    -0.     0.    -0.008]\n",
      " [-0.001 -0.003  0.    -0.     0.    -0.011]\n",
      " [-0.001 -0.003  0.    -0.     0.    -0.012]\n",
      " [-0.002 -0.004 -0.    -0.     0.    -0.016]\n",
      " [-0.002 -0.005  0.    -0.     0.    -0.018]\n",
      " [-0.001 -0.005  0.    -0.     0.    -0.018]\n",
      " [-0.002 -0.006  0.    -0.     0.    -0.02 ]\n",
      " [-0.002 -0.006 -0.    -0.     0.    -0.023]\n",
      " [-0.003 -0.007 -0.    -0.     0.    -0.027]\n",
      " [-0.003 -0.008  0.    -0.     0.    -0.03 ]\n",
      " [-0.003 -0.009  0.    -0.     0.    -0.032]\n",
      " [-0.003 -0.01   0.    -0.     0.    -0.036]\n",
      " [-0.004 -0.011 -0.    -0.     0.    -0.039]\n",
      " [-0.005 -0.012 -0.    -0.     0.    -0.044]\n",
      " [-0.004 -0.013  0.    -0.     0.    -0.046]\n",
      " [-0.005 -0.014  0.    -0.     0.    -0.052]\n",
      " [-0.005 -0.015  0.    -0.     0.    -0.056]\n",
      " [-0.006 -0.017 -0.    -0.     0.    -0.064]\n",
      " [-0.007 -0.018 -0.    -0.     0.    -0.072]\n",
      " [-0.007 -0.02   0.    -0.     0.    -0.08 ]\n",
      " [-0.007 -0.021  0.    -0.     0.    -0.086]\n",
      " [-0.008 -0.023  0.    -0.     0.    -0.094]\n",
      " [-0.009 -0.025 -0.    -0.     0.    -0.106]\n",
      " [-0.009 -0.026 -0.    -0.     0.    -0.113]\n",
      " [-0.009 -0.027  0.    -0.     0.    -0.122]\n",
      " [-0.009 -0.028  0.    -0.     0.    -0.13 ]\n",
      " [-0.009 -0.029  0.    -0.     0.    -0.141]\n",
      " [-0.01  -0.031 -0.    -0.     0.    -0.153]\n",
      " [-0.01  -0.032  0.    -0.     0.    -0.164]\n",
      " [-0.009 -0.033  0.    -0.     0.    -0.175]\n",
      " [-0.009 -0.034  0.    -0.     0.    -0.188]\n",
      " [-0.009 -0.035  0.    -0.     0.    -0.201]\n",
      " [-0.008 -0.037 -0.    -0.     0.    -0.218]\n",
      " [-0.006 -0.038  0.    -0.     0.    -0.239]\n",
      " [-0.004 -0.04   0.    -0.     0.    -0.255]\n",
      " [-0.002 -0.041  0.    -0.     0.    -0.27 ]\n",
      " [-0.    -0.043 -0.    -0.     0.    -0.286]\n",
      " [ 0.002 -0.044 -0.    -0.     0.    -0.301]\n",
      " [ 0.005 -0.045  0.    -0.     0.    -0.314]\n",
      " [ 0.008 -0.046  0.    -0.     0.    -0.324]\n",
      " [ 0.01  -0.048  0.    -0.     0.    -0.333]\n",
      " [ 0.01  -0.05  -0.    -0.     0.    -0.342]\n",
      " [ 0.011 -0.052 -0.    -0.     0.    -0.346]\n",
      " [ 0.013 -0.053  0.    -0.     0.    -0.349]\n",
      " [ 0.014 -0.054  0.    -0.     0.    -0.355]\n",
      " [ 0.015 -0.055  0.    -0.     0.    -0.364]\n",
      " [ 0.015 -0.057 -0.    -0.     0.    -0.373]\n",
      " [ 0.016 -0.058 -0.    -0.     0.    -0.383]\n",
      " [ 0.018 -0.059  0.    -0.     0.    -0.387]\n",
      " [ 0.019 -0.06   0.    -0.     0.    -0.393]\n",
      " [ 0.021 -0.062  0.    -0.     0.    -0.398]\n",
      " [ 0.021 -0.064 -0.    -0.     0.    -0.404]\n",
      " [ 0.024 -0.064  0.    -0.     0.    -0.406]\n",
      " [ 0.026 -0.066  0.    -0.     0.    -0.414]\n",
      " [ 0.028 -0.067  0.    -0.     0.    -0.418]\n",
      " [ 0.03  -0.069  0.    -0.     0.    -0.424]\n",
      " [ 0.031 -0.07  -0.    -0.     0.    -0.43 ]\n",
      " [ 0.034 -0.071  0.    -0.     0.    -0.431]]\n",
      "Initializing transformations\n"
     ]
    }
   ],
   "source": [
    "train_dataset = EpisodicDataset(dataset_path_list, camera_names, norm_stats, train_episode_ids, train_episode_len, chunk_size, policy_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ee_pose:  (65, 6)\n",
      "image_data:  torch.Size([3, 3, 480, 640])\n",
      "qpos_data:  torch.Size([4])\n",
      "action_data:  torch.Size([64, 5])\n",
      "end_pose_data:  torch.Size([64, 5])\n"
     ]
    }
   ],
   "source": [
    "index = 50\n",
    "image_data, qpos_data, action_data, is_pad, end_pose_data = train_dataset[0]\n",
    "print(\"image_data: \", image_data.shape)\n",
    "print(\"qpos_data: \", qpos_data.shape)\n",
    "print(\"action_data: \", action_data.shape)\n",
    "print(\"end_pose_data: \", end_pose_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import transformations as tf\n",
    "\n",
    "def batch_transform_to_xyzyrp_transformations(batch_transform):\n",
    "  \"\"\"\n",
    "  Converts a batch of transformation matrices (65, 4, 4) to a batch of (x, y, z, roll, pitch, yaw) (65, 6) using transformations library.\n",
    "\n",
    "  Note: This approach might have limitations and is not recommended as the primary method due to potential limitations in rotation order and axes supported.\n",
    "\n",
    "  Args:\n",
    "      batch_transform: A NumPy array of shape (batch_size, 4, 4) representing the batch of transformation matrices.\n",
    "\n",
    "  Returns:\n",
    "      A NumPy array of shape (batch_size, 6) containing the translation (x, y, z) and Euler angles (roll, pitch, yaw) for each transformation matrix.\n",
    "  \"\"\"\n",
    "  batch_xyzyrp = np.zeros((batch_transform.shape[0], 6))\n",
    "  for i in range(batch_transform.shape[0]):\n",
    "    matrix = batch_transform[i]\n",
    "    translation = matrix[:-1, 3]  # Extract translation (might be limited axes)\n",
    "    euler_angles = tf.euler_from_matrix(matrix, axes='sxyz')  # Might be limited axes\n",
    "\n",
    "    batch_xyzyrp[i] = np.concatenate([translation, euler_angles])\n",
    "  return batch_xyzyrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "trans_mats = np.asarray([np.diag([1, 1, 1, 1])] * 64)\n",
    "print(trans_mats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -0.,  0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_euler_angles = batch_transform_to_xyzyrp_transformations(trans_mats)\n",
    "batch_euler_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
