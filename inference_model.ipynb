{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No private macro file found!\n",
      "    It is recommended to use a private macro file\n",
      "    To setup, run: python /home/zfei/code/robomimic/robomimic/scripts/setup_macros.py\n",
      ")\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from itertools import repeat\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "import wandb\n",
    "import time\n",
    "from torchvision import transforms\n",
    "\n",
    "from brl_constants import FPS\n",
    "from brl_constants import PUPPET_GRIPPER_JOINT_OPEN\n",
    "from brl_constants import TASK_CONFIGS\n",
    "from utils import load_data # data functions\n",
    "from utils import sample_box_pose, sample_insertion_pose # robot functions\n",
    "from utils import compute_dict_mean, set_seed, detach_dict, calibrate_linear_vel, postprocess_base_action # helper functions\n",
    "from policy import ACTPolicy, CNNMLPPolicy\n",
    "# from policy import ACTPolicy, CNNMLPPolicy, DiffusionPolicy\n",
    "from visualize_episodes import save_videos\n",
    "\n",
    "from detr.models.latent_model import Latent_Model_Transformer\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"act_demo_z1_push_red\" \n",
    "task_config = TASK_CONFIGS[task_name]\n",
    "camera_names = task_config['camera_names']\n",
    "\n",
    "ckpt_dir = \"/mnt/data1/act/act_demo_z1_push_red/ckpt\" \n",
    "policy_class = \"ACT\" \n",
    "kl_weight = 10 \n",
    "chunk_size = 100 \n",
    "hidden_dim = 512 \n",
    "batch_size = 8 \n",
    "dim_feedforward = 3200 \n",
    "num_steps = 2000 \n",
    "lr = 1e-5 \n",
    "lr_backbone = 1e-5\n",
    "seed = 0\n",
    "backbone = 'resnet18'\n",
    "state_dim = 6\n",
    "enc_layers = 4\n",
    "dec_layers = 7\n",
    "nheads = 8\n",
    "\n",
    "policy_config = {'lr': lr,\n",
    "                'num_queries': chunk_size,\n",
    "                'kl_weight': kl_weight,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'dim_feedforward': dim_feedforward,\n",
    "                'lr_backbone': lr_backbone,\n",
    "                'backbone': backbone,\n",
    "                'enc_layers': enc_layers,\n",
    "                'dec_layers': dec_layers,\n",
    "                'nheads': nheads,\n",
    "                'camera_names': camera_names,\n",
    "                'vq': False,\n",
    "                'vq_class': None,\n",
    "                'vq_dim': None,\n",
    "                'action_dim': 6,\n",
    "                'no_encoder': False,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser('Set transformer detector', add_help=False)\n",
    "    parser.add_argument('--lr', default=1e-4, type=float) # will be overridden\n",
    "    parser.add_argument('--lr_backbone', default=1e-5, type=float) # will be overridden\n",
    "    parser.add_argument('--batch_size', default=2, type=int) # not used\n",
    "    parser.add_argument('--weight_decay', default=1e-4, type=float)\n",
    "    parser.add_argument('--epochs', default=300, type=int) # not used\n",
    "    parser.add_argument('--lr_drop', default=200, type=int) # not used\n",
    "    parser.add_argument('--clip_max_norm', default=0.1, type=float, # not used\n",
    "                        help='gradient clipping max norm')\n",
    "\n",
    "    # Model parameters\n",
    "    # * Backbone\n",
    "    parser.add_argument('--backbone', default='resnet18', type=str, # will be overridden\n",
    "                        help=\"Name of the convolutional backbone to use\")\n",
    "    parser.add_argument('--dilation', action='store_true',\n",
    "                        help=\"If true, we replace stride with dilation in the last convolutional block (DC5)\")\n",
    "    parser.add_argument('--position_embedding', default='sine', type=str, choices=('sine', 'learned'),\n",
    "                        help=\"Type of positional embedding to use on top of the image features\")\n",
    "    parser.add_argument('--camera_names', default=[], type=list, # will be overridden\n",
    "                        help=\"A list of camera names\")\n",
    "\n",
    "    # * Transformer\n",
    "    parser.add_argument('--enc_layers', default=4, type=int, # will be overridden\n",
    "                        help=\"Number of encoding layers in the transformer\")\n",
    "    parser.add_argument('--dec_layers', default=6, type=int, # will be overridden\n",
    "                        help=\"Number of decoding layers in the transformer\")\n",
    "    parser.add_argument('--dim_feedforward', default=2048, type=int, # will be overridden\n",
    "                        help=\"Intermediate size of the feedforward layers in the transformer blocks\")\n",
    "    parser.add_argument('--hidden_dim', default=256, type=int, # will be overridden\n",
    "                        help=\"Size of the embeddings (dimension of the transformer)\")\n",
    "    parser.add_argument('--dropout', default=0.1, type=float,\n",
    "                        help=\"Dropout applied in the transformer\")\n",
    "    parser.add_argument('--nheads', default=8, type=int, # will be overridden\n",
    "                        help=\"Number of attention heads inside the transformer's attentions\")\n",
    "    parser.add_argument('--num_queries', default=400, type=int, # will be overridden\n",
    "                        help=\"Number of query slots\")\n",
    "    parser.add_argument('--pre_norm', action='store_true')\n",
    "\n",
    "    # * Segmentation\n",
    "    parser.add_argument('--masks', action='store_true',\n",
    "                        help=\"Train segmentation head if the flag is provided\")\n",
    "\n",
    "    # repeat args in imitate_episodes just to avoid error. Will not be used\n",
    "    parser.add_argument('--eval', action='store_true')\n",
    "    parser.add_argument('--onscreen_render', action='store_true')\n",
    "    parser.add_argument('--ckpt_dir', action='store', type=str, help='ckpt_dir', required=False)\n",
    "    parser.add_argument('--policy_class', action='store', type=str, help='policy_class, capitalize', required=False)\n",
    "    parser.add_argument('--task_name', action='store', type=str, help='task_name', required=False)\n",
    "    parser.add_argument('--seed', action='store', type=int, help='seed', required=False)\n",
    "    parser.add_argument('--num_steps', action='store', type=int, help='num_epochs', required=False)\n",
    "    parser.add_argument('--kl_weight', action='store', type=int, help='KL Weight', required=False)\n",
    "    parser.add_argument('--chunk_size', action='store', type=int, help='chunk_size', required=False)\n",
    "    parser.add_argument('--temporal_agg', action='store_true')\n",
    "    \n",
    "    parser.add_argument('--use_vq', action='store_true')\n",
    "    parser.add_argument('--vq_class', action='store', type=int, help='vq_class', required=False)\n",
    "    parser.add_argument('--vq_dim', action='store', type=int, help='vq_dim', required=False)\n",
    "    parser.add_argument('--load_pretrain', action='store_true', default=False)\n",
    "    parser.add_argument('--action_dim', action='store', type=int, required=False)\n",
    "    parser.add_argument('--eval_every', action='store', type=int, default=500, help='eval_every', required=False)\n",
    "    parser.add_argument('--validate_every', action='store', type=int, default=500, help='validate_every', required=False)\n",
    "    parser.add_argument('--save_every', action='store', type=int, default=500, help='save_every', required=False)\n",
    "    parser.add_argument('--resume_ckpt_path', action='store', type=str, help='load_ckpt_path', required=False)\n",
    "    parser.add_argument('--no_encoder', action='store_true')\n",
    "    parser.add_argument('--skip_mirrored_data', action='store_true')\n",
    "    parser.add_argument('--actuator_network_dir', action='store', type=str, help='actuator_network_dir', required=False)\n",
    "    parser.add_argument('--history_len', action='store', type=int)\n",
    "    parser.add_argument('--future_len', action='store', type=int)\n",
    "    parser.add_argument('--prediction_len', action='store', type=int)\n",
    "    \n",
    "    return parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser('DETR training and evaluation script', parents=[get_args_parser()])\n",
    "args = parser.parse_args([\"--policy_class\", \"ACT\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_steps': 2000,\n",
       " 'eval_every': 500,\n",
       " 'validate_every': 500,\n",
       " 'save_every': 500,\n",
       " 'ckpt_dir': '/mnt/data1/act/act_demo_z1_push_red/ckpt',\n",
       " 'resume_ckpt_path': None,\n",
       " 'episode_len': 400,\n",
       " 'state_dim': 6,\n",
       " 'lr': 1e-05,\n",
       " 'policy_class': 'ACT',\n",
       " 'onscreen_render': False,\n",
       " 'policy_config': {'lr': 1e-05,\n",
       "  'num_queries': 100,\n",
       "  'kl_weight': 10,\n",
       "  'hidden_dim': 512,\n",
       "  'dim_feedforward': 3200,\n",
       "  'lr_backbone': 1e-05,\n",
       "  'backbone': 'resnet18',\n",
       "  'enc_layers': 4,\n",
       "  'dec_layers': 7,\n",
       "  'nheads': 8,\n",
       "  'camera_names': ['wrist'],\n",
       "  'vq': False,\n",
       "  'vq_class': None,\n",
       "  'vq_dim': None,\n",
       "  'action_dim': 6,\n",
       "  'no_encoder': False},\n",
       " 'task_name': 'act_demo_z1_push_red',\n",
       " 'seed': 0,\n",
       " 'temporal_agg': False,\n",
       " 'camera_names': ['wrist'],\n",
       " 'real_robot': True,\n",
       " 'load_pretrain': False,\n",
       " 'actuator_config': {'actuator_network_dir': None,\n",
       "  'history_len': None,\n",
       "  'future_len': None,\n",
       "  'prediction_len': None}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = \"/mnt/data1/act/act_demo_z1_push_red/ckpt/config.pkl\"\n",
    "with open(config_path, 'rb') as f:\n",
    "    policy_config = pickle.load(f)\n",
    "policy_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_config = {\n",
    "    \"lr\": 1e-05,\n",
    "    \"num_queries\": 100,\n",
    "    \"kl_weight\": 10,\n",
    "    \"hidden_dim\": 512,\n",
    "    \"dim_feedforward\": 3200,\n",
    "    \"lr_backbone\": 1e-05,\n",
    "    \"backbone\": \"resnet18\",\n",
    "    \"enc_layers\": 4,\n",
    "    \"dec_layers\": 7,\n",
    "    \"nheads\": 8,\n",
    "    \"camera_names\": [\"wrist\"],\n",
    "    \"vq\": False,\n",
    "    \"vq_class\": None,\n",
    "    \"vq_dim\": None,\n",
    "    \"action_dim\": 6,\n",
    "    \"no_encoder\": False,\n",
    "    \"task_name\": \"act_demo_z1_push_red\",\n",
    "    \"ckpt_dir\": \"/mnt/data1/act/act_demo_z1_push_red/ckpt/policy_best.ckpt\",\n",
    "    \"num_steps\": 2000,\n",
    "    \"lr\": 1e-5,\n",
    "    \"seed\":0,\n",
    "    \"policy_class\": \"ACT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETR Args:  Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=200, clip_max_norm=0.1, backbone='resnet18', dilation=False, position_embedding='sine', camera_names=[], enc_layers=4, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=400, pre_norm=False, masks=False, eval=False, onscreen_render=False, ckpt_dir='/mnt/data1/act/act_demo_z1_push_red/ckpt', policy_class='ACT', task_name='act_demo_z1_push_red', seed=0, num_steps=2000, kl_weight=None, chunk_size=None, temporal_agg=False, use_vq=False, vq_class=None, vq_dim=None, load_pretrain=False, action_dim=None, eval_every=500, validate_every=500, save_every=500, resume_ckpt_path=None, no_encoder=False, skip_mirrored_data=False, actuator_network_dir=None, history_len=None, future_len=None, prediction_len=None)\n",
      "ACT Args:  Namespace(lr=1e-05, lr_backbone=1e-05, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=200, clip_max_norm=0.1, backbone='resnet18', dilation=False, position_embedding='sine', camera_names=['wrist'], enc_layers=4, dec_layers=7, dim_feedforward=3200, hidden_dim=512, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, eval=False, onscreen_render=False, ckpt_dir='/mnt/data1/act/act_demo_z1_push_red/ckpt/policy_best.ckpt', policy_class='ACT', task_name='act_demo_z1_push_red', seed=0, num_steps=2000, kl_weight=10, chunk_size=None, temporal_agg=False, use_vq=False, vq_class=None, vq_dim=None, load_pretrain=False, action_dim=6, eval_every=500, validate_every=500, save_every=500, resume_ckpt_path=None, no_encoder=False, skip_mirrored_data=False, actuator_network_dir=None, history_len=None, future_len=None, prediction_len=None, vq=False)\n",
      "Use VQ: False, None, None\n",
      "number of parameters: 83.91M\n",
      "KL Weight 10\n",
      "<All keys matched successfully>\n",
      "Loaded:  /mnt/data1/act/act_demo_z1_push_red/ckpt/policy_best.ckpt\n"
     ]
    }
   ],
   "source": [
    "# ckpt_path = \"/mnt/data1/act/act_demo_z1_push_red/ckpt/policy_best.ckpt\"\n",
    "\n",
    "policy = ACTPolicy(policy_config)\n",
    "loading_status = policy.deserialize(torch.load(policy_config['ckpt_dir']))\n",
    "print(loading_status)\n",
    "policy.cuda()\n",
    "policy.eval()\n",
    "print('Loaded: ', policy_config['ckpt_dir'])\n",
    "stats_path = \"/mnt/data1/act/act_demo_z1_push_red/ckpt/dataset_stats.pkl\"\n",
    "with open(stats_path, 'rb') as f:\n",
    "    stats = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process = lambda s_qpos: (s_qpos - stats['qpos_mean']) / stats['qpos_std']\n",
    "post_process = lambda a: a * stats['action_std'] + stats['action_mean']\n",
    "query_frequency = policy_config['num_queries']\n",
    "BASE_DELAY = 13\n",
    "query_frequency -= BASE_DELAY\n",
    "max_timesteps = int(400) # may increase for real-world tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    time0 = time.time()\n",
    "    DT = 1 / FPS\n",
    "    culmulated_delay = 0 \n",
    "    for t in range(max_timesteps):\n",
    "        all_actions = policy(qpos, curr_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5data_file = \"/mnt/data1/act/act_demo_z1_push_red/episode_50.hdf5\"\n",
    "f = h5py.File(h5_paths[0], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
