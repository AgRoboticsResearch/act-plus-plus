{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from itertools import repeat\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "import wandb\n",
    "import time\n",
    "from torchvision import transforms\n",
    "import h5py\n",
    "import cv2 as cv\n",
    "from brl_constants import FPS\n",
    "from brl_constants import PUPPET_GRIPPER_JOINT_OPEN\n",
    "from brl_constants import TASK_CONFIGS\n",
    "from utils import load_data  # data functions\n",
    "from utils import sample_box_pose, sample_insertion_pose  # robot functions\n",
    "from utils import (\n",
    "    compute_dict_mean,\n",
    "    set_seed,\n",
    "    detach_dict,\n",
    "    calibrate_linear_vel,\n",
    "    postprocess_base_action,\n",
    ")  # helper functions\n",
    "from policy import ACTPolicy, CNNMLPPolicy\n",
    "\n",
    "# from policy import ACTPolicy, CNNMLPPolicy, DiffusionPolicy\n",
    "from visualize_episodes import save_videos\n",
    "\n",
    "from detr.models.latent_model import Latent_Model_Transformer\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"act_demo_z1_push_red\"\n",
    "task_config = TASK_CONFIGS[task_name]\n",
    "camera_names = task_config[\"camera_names\"]\n",
    "\n",
    "ckpt_dir = \"/mnt/data1/act/act_demo_z1_push_red/ckpt\"\n",
    "policy_class = \"ACT\"\n",
    "kl_weight = 10\n",
    "chunk_size = 100\n",
    "hidden_dim = 512\n",
    "batch_size = 8\n",
    "dim_feedforward = 3200\n",
    "num_steps = 2000\n",
    "lr = 1e-5\n",
    "lr_backbone = 1e-5\n",
    "seed = 0\n",
    "backbone = \"resnet18\"\n",
    "state_dim = 6\n",
    "enc_layers = 4\n",
    "dec_layers = 7\n",
    "nheads = 8\n",
    "\n",
    "policy_config = {\n",
    "    \"lr\": lr,\n",
    "    \"num_queries\": chunk_size,\n",
    "    \"kl_weight\": kl_weight,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"dim_feedforward\": dim_feedforward,\n",
    "    \"lr_backbone\": lr_backbone,\n",
    "    \"backbone\": backbone,\n",
    "    \"enc_layers\": enc_layers,\n",
    "    \"dec_layers\": dec_layers,\n",
    "    \"nheads\": nheads,\n",
    "    \"camera_names\": camera_names,\n",
    "    \"vq\": False,\n",
    "    \"vq_class\": None,\n",
    "    \"vq_dim\": None,\n",
    "    \"action_dim\": 6,\n",
    "    \"no_encoder\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser(\"Set transformer detector\", add_help=False)\n",
    "    parser.add_argument(\"--lr\", default=1e-4, type=float)  # will be overridden\n",
    "    parser.add_argument(\"--lr_backbone\", default=1e-5, type=float)  # will be overridden\n",
    "    parser.add_argument(\"--batch_size\", default=2, type=int)  # not used\n",
    "    parser.add_argument(\"--weight_decay\", default=1e-4, type=float)\n",
    "    parser.add_argument(\"--epochs\", default=300, type=int)  # not used\n",
    "    parser.add_argument(\"--lr_drop\", default=200, type=int)  # not used\n",
    "    parser.add_argument(\n",
    "        \"--clip_max_norm\",\n",
    "        default=0.1,\n",
    "        type=float,  # not used\n",
    "        help=\"gradient clipping max norm\",\n",
    "    )\n",
    "\n",
    "    # Model parameters\n",
    "    # * Backbone\n",
    "    parser.add_argument(\n",
    "        \"--backbone\",\n",
    "        default=\"resnet18\",\n",
    "        type=str,  # will be overridden\n",
    "        help=\"Name of the convolutional backbone to use\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dilation\",\n",
    "        action=\"store_true\",\n",
    "        help=\"If true, we replace stride with dilation in the last convolutional block (DC5)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--position_embedding\",\n",
    "        default=\"sine\",\n",
    "        type=str,\n",
    "        choices=(\"sine\", \"learned\"),\n",
    "        help=\"Type of positional embedding to use on top of the image features\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--camera_names\",\n",
    "        default=[],\n",
    "        type=list,  # will be overridden\n",
    "        help=\"A list of camera names\",\n",
    "    )\n",
    "\n",
    "    # * Transformer\n",
    "    parser.add_argument(\n",
    "        \"--enc_layers\",\n",
    "        default=4,\n",
    "        type=int,  # will be overridden\n",
    "        help=\"Number of encoding layers in the transformer\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dec_layers\",\n",
    "        default=6,\n",
    "        type=int,  # will be overridden\n",
    "        help=\"Number of decoding layers in the transformer\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dim_feedforward\",\n",
    "        default=2048,\n",
    "        type=int,  # will be overridden\n",
    "        help=\"Intermediate size of the feedforward layers in the transformer blocks\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--hidden_dim\",\n",
    "        default=256,\n",
    "        type=int,  # will be overridden\n",
    "        help=\"Size of the embeddings (dimension of the transformer)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dropout\", default=0.1, type=float, help=\"Dropout applied in the transformer\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--nheads\",\n",
    "        default=8,\n",
    "        type=int,  # will be overridden\n",
    "        help=\"Number of attention heads inside the transformer's attentions\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_queries\",\n",
    "        default=400,\n",
    "        type=int,  # will be overridden\n",
    "        help=\"Number of query slots\",\n",
    "    )\n",
    "    parser.add_argument(\"--pre_norm\", action=\"store_true\")\n",
    "\n",
    "    # * Segmentation\n",
    "    parser.add_argument(\n",
    "        \"--masks\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Train segmentation head if the flag is provided\",\n",
    "    )\n",
    "\n",
    "    # repeat args in imitate_episodes just to avoid error. Will not be used\n",
    "    parser.add_argument(\"--eval\", action=\"store_true\")\n",
    "    parser.add_argument(\"--onscreen_render\", action=\"store_true\")\n",
    "    parser.add_argument(\n",
    "        \"--ckpt_dir\", action=\"store\", type=str, help=\"ckpt_dir\", required=False\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--policy_class\",\n",
    "        action=\"store\",\n",
    "        type=str,\n",
    "        help=\"policy_class, capitalize\",\n",
    "        required=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--task_name\", action=\"store\", type=str, help=\"task_name\", required=False\n",
    "    )\n",
    "    parser.add_argument(\"--seed\", action=\"store\", type=int, help=\"seed\", required=False)\n",
    "    parser.add_argument(\n",
    "        \"--num_steps\", action=\"store\", type=int, help=\"num_epochs\", required=False\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--kl_weight\", action=\"store\", type=int, help=\"KL Weight\", required=False\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--chunk_size\", action=\"store\", type=int, help=\"chunk_size\", required=False\n",
    "    )\n",
    "    parser.add_argument(\"--temporal_agg\", action=\"store_true\")\n",
    "\n",
    "    parser.add_argument(\"--use_vq\", action=\"store_true\")\n",
    "    parser.add_argument(\n",
    "        \"--vq_class\", action=\"store\", type=int, help=\"vq_class\", required=False\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--vq_dim\", action=\"store\", type=int, help=\"vq_dim\", required=False\n",
    "    )\n",
    "    parser.add_argument(\"--load_pretrain\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--action_dim\", action=\"store\", type=int, required=False)\n",
    "    parser.add_argument(\n",
    "        \"--eval_every\",\n",
    "        action=\"store\",\n",
    "        type=int,\n",
    "        default=500,\n",
    "        help=\"eval_every\",\n",
    "        required=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--validate_every\",\n",
    "        action=\"store\",\n",
    "        type=int,\n",
    "        default=500,\n",
    "        help=\"validate_every\",\n",
    "        required=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--save_every\",\n",
    "        action=\"store\",\n",
    "        type=int,\n",
    "        default=500,\n",
    "        help=\"save_every\",\n",
    "        required=False,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--resume_ckpt_path\",\n",
    "        action=\"store\",\n",
    "        type=str,\n",
    "        help=\"load_ckpt_path\",\n",
    "        required=False,\n",
    "    )\n",
    "    parser.add_argument(\"--no_encoder\", action=\"store_true\")\n",
    "    parser.add_argument(\"--skip_mirrored_data\", action=\"store_true\")\n",
    "    parser.add_argument(\n",
    "        \"--actuator_network_dir\",\n",
    "        action=\"store\",\n",
    "        type=str,\n",
    "        help=\"actuator_network_dir\",\n",
    "        required=False,\n",
    "    )\n",
    "    parser.add_argument(\"--history_len\", action=\"store\", type=int)\n",
    "    parser.add_argument(\"--future_len\", action=\"store\", type=int)\n",
    "    parser.add_argument(\"--prediction_len\", action=\"store\", type=int)\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    \"DETR training and evaluation script\", parents=[get_args_parser()]\n",
    ")\n",
    "args = parser.parse_args([\"--policy_class\", \"ACT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_steps': 2000,\n",
       " 'eval_every': 500,\n",
       " 'validate_every': 500,\n",
       " 'save_every': 500,\n",
       " 'ckpt_dir': '/mnt/data1/act/act_demo_z1_push_red/ckpt',\n",
       " 'resume_ckpt_path': None,\n",
       " 'episode_len': 400,\n",
       " 'state_dim': 6,\n",
       " 'lr': 1e-05,\n",
       " 'policy_class': 'ACT',\n",
       " 'onscreen_render': False,\n",
       " 'policy_config': {'lr': 1e-05,\n",
       "  'num_queries': 100,\n",
       "  'kl_weight': 10,\n",
       "  'hidden_dim': 512,\n",
       "  'dim_feedforward': 3200,\n",
       "  'lr_backbone': 1e-05,\n",
       "  'backbone': 'resnet18',\n",
       "  'enc_layers': 4,\n",
       "  'dec_layers': 7,\n",
       "  'nheads': 8,\n",
       "  'camera_names': ['wrist'],\n",
       "  'vq': False,\n",
       "  'vq_class': None,\n",
       "  'vq_dim': None,\n",
       "  'action_dim': 6,\n",
       "  'no_encoder': False},\n",
       " 'task_name': 'act_demo_z1_push_red',\n",
       " 'seed': 0,\n",
       " 'temporal_agg': False,\n",
       " 'camera_names': ['wrist'],\n",
       " 'real_robot': True,\n",
       " 'load_pretrain': False,\n",
       " 'actuator_config': {'actuator_network_dir': None,\n",
       "  'history_len': None,\n",
       "  'future_len': None,\n",
       "  'prediction_len': None}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = \"/mnt/data1/act/act_demo_z1_push_red/ckpt/config.pkl\"\n",
    "with open(config_path, \"rb\") as f:\n",
    "    policy_config = pickle.load(f)\n",
    "policy_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_config = {\n",
    "    \"lr\": 1e-05,\n",
    "    \"num_queries\": 100,\n",
    "    \"kl_weight\": 10,\n",
    "    \"hidden_dim\": 512,\n",
    "    \"dim_feedforward\": 3200,\n",
    "    \"lr_backbone\": 1e-05,\n",
    "    \"backbone\": \"resnet18\",\n",
    "    \"enc_layers\": 4,\n",
    "    \"dec_layers\": 7,\n",
    "    \"nheads\": 8,\n",
    "    \"camera_names\": [\"wrist\"],\n",
    "    \"vq\": False,\n",
    "    \"vq_class\": None,\n",
    "    \"vq_dim\": None,\n",
    "    \"action_dim\": 6,\n",
    "    \"no_encoder\": False,\n",
    "    \"task_name\": \"act_demo_z1_push_red\",\n",
    "    \"ckpt_dir\": \"/mnt/data1/act/act_demo_z1_push_red/ckpt/policy_best.ckpt\",\n",
    "    \"num_steps\": 2000,\n",
    "    \"lr\": 1e-5,\n",
    "    \"seed\": 0,\n",
    "    \"policy_class\": \"ACT\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETR Args:  Namespace(lr=0.0001, lr_backbone=1e-05, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=200, clip_max_norm=0.1, backbone='resnet18', dilation=False, position_embedding='sine', camera_names=[], enc_layers=4, dec_layers=6, dim_feedforward=2048, hidden_dim=256, dropout=0.1, nheads=8, num_queries=400, pre_norm=False, masks=False, eval=False, onscreen_render=False, ckpt_dir='/mnt/data1/act/act_demo_z1_push_red/ckpt', policy_class='ACT', task_name='act_demo_z1_push_red', seed=0, num_steps=2000, kl_weight=None, chunk_size=None, temporal_agg=False, use_vq=False, vq_class=None, vq_dim=None, load_pretrain=False, action_dim=None, eval_every=500, validate_every=500, save_every=500, resume_ckpt_path=None, no_encoder=False, skip_mirrored_data=False, actuator_network_dir=None, history_len=None, future_len=None, prediction_len=None)\n",
      "ACT Args:  Namespace(lr=1e-05, lr_backbone=1e-05, batch_size=2, weight_decay=0.0001, epochs=300, lr_drop=200, clip_max_norm=0.1, backbone='resnet18', dilation=False, position_embedding='sine', camera_names=['wrist'], enc_layers=4, dec_layers=7, dim_feedforward=3200, hidden_dim=512, dropout=0.1, nheads=8, num_queries=100, pre_norm=False, masks=False, eval=False, onscreen_render=False, ckpt_dir='/mnt/data1/act/act_demo_z1_push_red/ckpt/policy_best.ckpt', policy_class='ACT', task_name='act_demo_z1_push_red', seed=0, num_steps=2000, kl_weight=10, chunk_size=None, temporal_agg=False, use_vq=False, vq_class=None, vq_dim=None, load_pretrain=False, action_dim=6, eval_every=500, validate_every=500, save_every=500, resume_ckpt_path=None, no_encoder=False, skip_mirrored_data=False, actuator_network_dir=None, history_len=None, future_len=None, prediction_len=None, vq=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zfei/anaconda3/envs/torch/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/zfei/anaconda3/envs/torch/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use VQ: False, None, None\n",
      "number of parameters: 83.91M\n",
      "KL Weight 10\n",
      "<All keys matched successfully>\n",
      "Loaded:  /mnt/data1/act/act_demo_z1_push_red/ckpt/policy_best.ckpt\n"
     ]
    }
   ],
   "source": [
    "# ckpt_path = \"/mnt/data1/act/act_demo_z1_push_red/ckpt/policy_best.ckpt\"\n",
    "\n",
    "policy = ACTPolicy(policy_config)\n",
    "loading_status = policy.deserialize(torch.load(policy_config[\"ckpt_dir\"]))\n",
    "print(loading_status)\n",
    "policy.cuda()\n",
    "policy.eval()\n",
    "print(\"Loaded: \", policy_config[\"ckpt_dir\"])\n",
    "stats_path = \"/mnt/data1/act/act_demo_z1_push_red/ckpt/dataset_stats.pkl\"\n",
    "with open(stats_path, \"rb\") as f:\n",
    "    stats = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_process_qpos = (\n",
    "    lambda s_qpos: torch.from_numpy((s_qpos - stats[\"qpos_mean\"]) / stats[\"qpos_std\"])\n",
    "    .float()\n",
    "    .cuda()\n",
    "    .unsqueeze(0)\n",
    ")\n",
    "post_process_action = lambda a: a * stats[\"action_std\"] + stats[\"action_mean\"]\n",
    "query_frequency = policy_config[\"num_queries\"]\n",
    "BASE_DELAY = 13\n",
    "query_frequency -= BASE_DELAY\n",
    "max_timesteps = int(400)  # may increase for real-world tasks\n",
    "\n",
    "\n",
    "def pre_proccess_img(img):\n",
    "    img_torch = torch.from_numpy(img).unsqueeze(0)\n",
    "    img_torch = torch.einsum(\"k h w c -> k c h w\", img_torch)\n",
    "    img_torch = (img_torch / 255.0).float().cuda().unsqueeze(0)\n",
    "    return img_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'curr_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m culmulated_delay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_timesteps):\n\u001b[0;32m----> 6\u001b[0m     all_actions \u001b[38;5;241m=\u001b[39m policy(qpos, \u001b[43mcurr_image\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'curr_image' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    time0 = time.time()\n",
    "    DT = 1 / FPS\n",
    "    culmulated_delay = 0\n",
    "    for t in range(max_timesteps):\n",
    "        all_actions = policy(qpos, curr_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave inference time: 0.008824615478515626\n",
      "ave fps: 113.31442555046989\n"
     ]
    }
   ],
   "source": [
    "h5data_file = \"/mnt/data1/act/act_demo_z1_push_red/episode_50.hdf5\"\n",
    "with torch.inference_mode():\n",
    "    with h5py.File(h5data_file, \"r\") as root:\n",
    "        tic = time.time()\n",
    "        for index in range(100):\n",
    "            qpos_np = root[\"/observations/qpos\"][index]\n",
    "            img_np = root[\"/observations/images/wrist\"][index]\n",
    "            qpos = pre_process_qpos(qpos_np)\n",
    "            curr_img = pre_proccess_img(img_np)\n",
    "            # print(\"qpos: \",qpos.shape)\n",
    "            # print(\"curr_img: \",curr_img.shape)\n",
    "            all_actions = policy(qpos, curr_img)\n",
    "            # print(\"all_actions: \", all_actions.shape)\n",
    "        print(\"ave inference time:\", (time.time()-tic)/100)\n",
    "        print(\"ave fps:\", 100/(time.time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual action 0 [-0.27048644  0.28409767 -1.3577642   1.0764028   0.26963568  0.00364211]\n",
      "actual action 1 [-0.27048752  0.28410238 -1.357761    1.0763901   0.2696367   0.00364215]\n",
      "actual action 2 [-0.2705621   0.2836768  -1.3582773   1.0780164   0.26963714  0.00363334]\n",
      "actual action 3 [-0.27061105  0.2891059  -1.3531578   1.0689373   0.27101272  0.00433012]\n",
      "actual action 4 [-0.27016604  0.31722903 -1.3378539   1.0374017   0.27179506  0.00484861]\n",
      "actual action 5 [-0.27019146  0.31718796 -1.3378454   1.0374027   0.27181014  0.0048494 ]\n",
      "actual action 6 [-0.27219585  0.3273734  -1.3273525   1.0072116   0.27330372  0.00488721]\n",
      "actual action 7 [-0.27810234  0.35023183 -1.3025774   0.9570044   0.27953658  0.00487137]\n",
      "actual action 8 [-0.281964    0.36514717 -1.2856654   0.92124915  0.28307167  0.00488848]\n",
      "actual action 9 [-0.28510687  0.3823722  -1.269188    0.88054186  0.28775796  0.00490073]\n",
      "actual action 10 [-0.2853763   0.38249648 -1.2684586   0.87936634  0.28799316  0.00490519]\n",
      "actual action 11 [-0.28929773  0.40040982 -1.2498293   0.8417674   0.29225773  0.0049445 ]\n",
      "actual action 12 [-0.29602438  0.4204098  -1.2261221   0.79141486  0.30025417  0.00483518]\n",
      "actual action 13 [-0.29650217  0.4208935  -1.2248503   0.789078    0.3006928   0.00483594]\n",
      "actual action 14 [-0.30701506  0.47714803 -1.1695752   0.6700178   0.31184888  0.00496202]\n",
      "actual action 15 [-0.3084663   0.47893313 -1.1653872   0.6638512   0.31311348  0.00494202]\n",
      "actual action 16 [-0.30727857  0.47796607 -1.1634668   0.6468204   0.31423143  0.00489881]\n",
      "actual action 17 [-0.31682697  0.52467394 -1.122036    0.5641761   0.32170194  0.00472114]\n",
      "actual action 18 [-0.3178098   0.5259832  -1.1191113   0.559445    0.32254273  0.00471001]\n",
      "actual action 19 [-0.32731545  0.59022564 -1.0564473   0.43400192  0.33321562  0.00437248]\n",
      "actual action 20 [-0.33761114  0.62854093 -1.0097632   0.33082852  0.3439711   0.00374377]\n",
      "actual action 21 [-0.33903843  0.6307361  -1.0055146   0.32510838  0.34534514  0.00371204]\n",
      "actual action 22 [-0.3368852   0.6208334  -1.0177925   0.35758963  0.3437972   0.00405638]\n",
      "actual action 23 [-0.34296748  0.7422339  -0.9361991   0.1646908   0.35128394  0.00320629]\n",
      "actual action 24 [-0.3449277   0.7438386  -0.9306677   0.15833372  0.35322165  0.00315381]\n",
      "actual action 25 [-0.35097435  0.67054534 -0.9555414   0.26208392  0.3558335   0.00387911]\n",
      "actual action 26 [-0.35688576  0.7157526  -0.92411536  0.15754429  0.36033985  0.00281602]\n",
      "actual action 27 [-0.3597396   0.8306568  -0.855007   -0.00215293  0.36660868  0.0026907 ]\n",
      "actual action 28 [-0.37607822  0.80192816 -0.8319624  -0.00486283  0.37636745  0.00247176]\n",
      "actual action 29 [-0.38009015  0.80640364 -0.819994   -0.02105965  0.37997225  0.00230835]\n",
      "actual action 30 [-0.3791885   0.86853755 -0.7928108  -0.0995827   0.38151392  0.00208671]\n",
      "actual action 31 [-0.38594717  0.90676725 -0.7570456  -0.16970354  0.38903797  0.00187192]\n",
      "actual action 32 [-0.39113832  0.8372404  -0.77673167 -0.08932801  0.390376    0.00149083]\n",
      "actual action 33 [-0.39520472  0.84860957 -0.759994   -0.11556034  0.39364353  0.00128926]\n",
      "actual action 34 [-0.39984378  0.9036134  -0.71331596 -0.20606121  0.40000057  0.00102569]\n",
      "actual action 35 [-4.0532818e-01  9.4612676e-01 -6.8046385e-01 -2.8313708e-01\n",
      "  4.0625978e-01  8.5137156e-04]\n",
      "actual action 36 [-4.0768558e-01  9.5373613e-01 -6.7029512e-01 -2.9766762e-01\n",
      "  4.0848601e-01  6.6668983e-04]\n",
      "actual action 37 [-4.1169965e-01  9.5506829e-01 -6.6219914e-01 -3.0238247e-01\n",
      "  4.0828851e-01  6.1276788e-04]\n",
      "actual action 38 [-4.1820875e-01  9.8005712e-01 -6.2774014e-01 -3.6330366e-01\n",
      "  4.1486847e-01  6.1295251e-04]\n",
      "actual action 39 [-4.2050543e-01  9.8774928e-01 -6.2014174e-01 -3.7958077e-01\n",
      "  4.1670865e-01  5.4253591e-04]\n",
      "actual action 40 [-4.1896164e-01  9.9041176e-01 -6.2163591e-01 -3.9065331e-01\n",
      "  4.1681594e-01  4.1345321e-04]\n",
      "actual action 41 [-4.2812529e-01  1.0141448e+00 -5.9011918e-01 -4.3405929e-01\n",
      "  4.2609113e-01  3.7662685e-06]\n",
      "actual action 42 [-4.2909014e-01  1.0164027e+00 -5.8767045e-01 -4.3874246e-01\n",
      "  4.2665023e-01 -1.2132339e-05]\n",
      "actual action 43 [-4.2599377e-01  1.0244852e+00 -5.9463394e-01 -4.3892419e-01\n",
      "  4.2592382e-01  2.9182667e-04]\n",
      "actual action 44 [-4.3560627e-01  1.0392932e+00 -5.6243467e-01 -4.9146837e-01\n",
      "  4.3379655e-01  1.4482066e-06]\n",
      "actual action 45 [-4.3604693e-01  1.0404475e+00 -5.6138599e-01 -4.9252200e-01\n",
      "  4.3410960e-01  6.9895759e-07]\n",
      "actual action 46 [-4.3691632e-01  1.0421832e+00 -5.5890441e-01 -4.9824253e-01\n",
      "  4.3505719e-01  3.9964681e-05]\n",
      "actual action 47 [-4.4098666e-01  1.0537581e+00 -5.4648972e-01 -5.2771384e-01\n",
      "  4.3969724e-01  1.1794595e-04]\n",
      "actual action 48 [-4.4200361e-01  1.0557380e+00 -5.4327518e-01 -5.3555638e-01\n",
      "  4.4051236e-01  3.4660078e-04]\n",
      "actual action 49 [-4.4285497e-01  1.0615407e+00 -5.3420460e-01 -5.5165911e-01\n",
      "  4.4202363e-01  2.2929511e-04]\n",
      "actual action 50 [-4.4188577e-01  1.0580373e+00 -5.3812921e-01 -5.4342216e-01\n",
      "  4.4053620e-01  2.7273525e-04]\n",
      "actual action 51 [-4.4231367e-01  1.0550678e+00 -5.3998876e-01 -5.3687882e-01\n",
      "  4.4039720e-01  5.9923576e-04]\n",
      "actual action 52 [-4.4390529e-01  1.0713810e+00 -5.3260535e-01 -5.5882275e-01\n",
      "  4.4499806e-01  1.0513566e-03]\n",
      "actual action 53 [-4.4401884e-01  1.0714681e+00 -5.3242391e-01 -5.5915433e-01\n",
      "  4.4507229e-01  1.0544378e-03]\n",
      "actual action 54 [-0.44387457  1.0708361  -0.53241545 -0.549628    0.44504488  0.00133722]\n",
      "actual action 55 [-0.4439099   1.0763365  -0.5303772  -0.54486585  0.44361022  0.00186321]\n",
      "actual action 56 [-0.44391936  1.0763421  -0.53036475 -0.544879    0.44361743  0.00186367]\n",
      "actual action 57 [-0.4435373   1.0772725  -0.5299147  -0.54248846  0.4428957   0.00204072]\n",
      "actual action 58 [-0.44250864  1.0785382  -0.5299753  -0.542359    0.44104034  0.00229255]\n",
      "actual action 59 [-0.44251096  1.078539   -0.5299691  -0.5423744   0.4410426   0.0022926 ]\n",
      "actual action 60 [-0.4419141   1.0793957  -0.5298218  -0.5426548   0.44027555  0.00244583]\n",
      "actual action 61 [-0.44174474  1.0805378  -0.5300801  -0.54444945  0.43968293  0.00248249]\n",
      "actual action 62 [-0.44208324  1.0809292  -0.52923644 -0.544634    0.43998444  0.00245716]\n",
      "actual action 63 [-0.44208562  1.0809293  -0.52923036 -0.5446516   0.43998682  0.00245715]\n",
      "actual action 64 [-0.44149607  1.0800602  -0.5300166  -0.53893864  0.44018742  0.00257293]\n",
      "actual action 65 [-0.4415136   1.0803231  -0.52973604 -0.53908545  0.44007462  0.00258873]\n",
      "actual action 66 [-0.44131345  1.0813302  -0.5296004  -0.5387881   0.43968382  0.00270859]\n",
      "actual action 67 [-0.44072473  1.0810943  -0.5287785  -0.53876173  0.43916118  0.00280588]\n",
      "actual action 68 [-0.44072688  1.0810941  -0.5287732  -0.538777    0.43916306  0.00280588]\n",
      "actual action 69 [-0.4398206   1.0842415  -0.52951735 -0.5392828   0.43780482  0.00296946]\n",
      "actual action 70 [-0.4473446   1.0571135  -0.5244094  -0.57571065  0.4430559   0.0026855 ]\n",
      "actual action 71 [-0.4231665   1.1019447  -0.5538593  -0.5535011   0.4208535   0.00402057]\n",
      "actual action 72 [-0.422836    1.1019253  -0.55456215 -0.55251026  0.4205522   0.00402274]\n",
      "actual action 73 [-0.409271    1.1323003  -0.56746364 -0.5739217   0.40410995  0.00433124]\n",
      "actual action 74 [-0.4110956   1.1373913  -0.56554395 -0.5828713   0.4045573   0.00461834]\n",
      "actual action 75 [-0.39911577  1.1746794  -0.581537   -0.6022804   0.39013708  0.00501993]\n",
      "actual action 76 [-0.38523743  1.1993675  -0.5991786  -0.606274    0.37547538  0.00500804]\n",
      "actual action 77 [-0.3661141   1.2301027  -0.61312604 -0.61382407  0.3579035   0.00508548]\n",
      "actual action 78 [-0.3606963   1.2383072  -0.6191731  -0.61733896  0.35290742  0.00506933]\n",
      "actual action 79 [-0.34588555  1.276396   -0.63258153 -0.6285055   0.33721995  0.00522071]\n",
      "actual action 80 [-0.3237856   1.3288543  -0.65803427 -0.6498221   0.3160144   0.00519468]\n",
      "actual action 81 [-0.31403935  1.3487324  -0.6680753  -0.65658647  0.30662605  0.00512811]\n",
      "actual action 82 [-0.28162146  1.4193405  -0.7013289  -0.6909608   0.2769822   0.00506155]\n",
      "actual action 83 [-0.27987653  1.4255736  -0.7023736  -0.6925616   0.27273345  0.00490447]\n",
      "actual action 84 [-0.26859376  1.4516444  -0.7116148  -0.7074087   0.26171374  0.00481968]\n",
      "actual action 85 [-0.2558101   1.474794   -0.7202468  -0.72839737  0.25046548  0.00471731]\n",
      "actual action 86 [-0.24115273  1.5047784  -0.7334423  -0.75111175  0.23575261  0.00458801]\n",
      "actual action 87 [-0.22394843  1.53914    -0.7561914  -0.7713051   0.22021885  0.00445869]\n",
      "actual action 88 [-0.22096097  1.5438086  -0.75940275 -0.7732244   0.21739277  0.00443472]\n",
      "actual action 89 [-0.21480525  1.5562208  -0.7644973  -0.7882073   0.21379194  0.00428216]\n",
      "actual action 90 [-0.212778    1.5591091  -0.7665718  -0.7892086   0.21196681  0.00427143]\n",
      "actual action 91 [-0.19840962  1.5914426  -0.78203833 -0.7984677   0.19702096  0.00401548]\n",
      "actual action 92 [-0.19721821  1.5930007  -0.78314835 -0.79918534  0.19594426  0.00399654]\n",
      "actual action 93 [-0.18307582  1.6115172  -0.79952955 -0.81616193  0.18432726  0.00393193]\n",
      "actual action 94 [-0.17969234  1.6079683  -0.79743123 -0.8155723   0.18270643  0.00401653]\n",
      "actual action 95 [-0.1792915   1.6087081  -0.7977888  -0.81575173  0.18227449  0.00401103]\n",
      "actual action 96 [-0.17179742  1.6117772  -0.8076365  -0.8182789   0.1743514   0.00386306]\n",
      "actual action 97 [-0.17151847  1.6057725  -0.8121261  -0.8062841   0.17243643  0.00365556]\n",
      "actual action 98 [-0.17140785  1.6059449  -0.81225055 -0.8063331   0.17232512  0.00365374]\n",
      "actual action 99 [-0.17154363  1.5977902  -0.8145235  -0.799076    0.17225395  0.00370568]\n",
      "ave inference time: 0.005763165950775147\n"
     ]
    }
   ],
   "source": [
    "h5data_file = \"/mnt/data1/act/act_demo_z1_push_red/episode_50.hdf5\"\n",
    "with torch.inference_mode():\n",
    "    with h5py.File(h5data_file, \"r\") as root:\n",
    "        tic = time.time()\n",
    "        for index in range(100):\n",
    "            qpos_np = root[\"/observations/qpos\"][index]\n",
    "            img_np = root[\"/observations/images/wrist\"][index]\n",
    "            qpos = pre_process_qpos(qpos_np)\n",
    "            curr_img = pre_proccess_img(img_np)\n",
    "            # print(\"qpos: \",qpos.shape)\n",
    "            # print(\"curr_img: \",curr_img.shape)\n",
    "            all_actions = policy(qpos, curr_img)\n",
    "            # print(\"all_actions: \", all_actions.shape)\n",
    "\n",
    "            raw_action = all_actions[:, 0]\n",
    "            raw_action = raw_action.squeeze(0).cpu().numpy()\n",
    "            actual_action = post_process_action(raw_action)\n",
    "            print(\"actual action %i\"%index, actual_action)\n",
    "\n",
    "        print(\"ave inference time:\", (time.time()-tic)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 480, 640])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6369, -1.5069, -1.7223,  1.7077, -0.6148,  0.0204]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_process(qpos_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    time0 = time.time()\n",
    "    DT = 1 / FPS\n",
    "    culmulated_delay = 0\n",
    "    all_actions = policy(qpos, curr_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
